{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7a8c8ae",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center\">ViT</h1>\n",
    "<p style=\"text-align:center\">\n",
    "    <span>create time: 2024-11-01</span>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "    <span>last update: 2024-12-02</span>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2481b37d",
   "metadata": {},
   "source": [
    "## 摘要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb9aaa1",
   "metadata": {},
   "source": [
    "自2012年AlexNet问世以来，CNN一直是CV任务的首选模型。而后，为了实现多个领域（CV、NLP、Audio）模型的大一统，Google试探性地迈出了一步，它参考NLP领域的Transformer架构，提出了Vision Transformer（ViT），ViT将输入图像表示为图像块序列（sequence of image patches），类似于文本任务的token sequence，然后直接预测图像的类别标签。当在足够的数据上进行训练时，ViT表现非常出色，仅需SOTA CNN模型1/4的计算资源就取得了更好的成绩。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a45b3b",
   "metadata": {},
   "source": [
    "ViT的模型架构如下图所示："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67d1e9b",
   "metadata": {},
   "source": [
    "![b](905ab5b5-e061-41d1-ab48-bb47d57cb218.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4003f6df",
   "metadata": {},
   "source": [
    "计算流程：\n",
    "\n",
    "1. 首先将图片分割成固定数量的patch；\n",
    "2. 将patch flatten成向量并做线性映射；\n",
    "3. 加上位置编码；\n",
    "4. 将得到的向量序列输入到标准的Transformer Encoder中去。\n",
    "\n",
    "为了完成图片分类任务，在最开始的地方增加一个额外的token，如上图所示。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e57bc59",
   "metadata": {},
   "source": [
    "### Scale Up\n",
    "\n",
    "在ImageNet上训练ViT达到了77.9%的top-1准确率。虽然这对于第一次尝试来说是不错的，但它远远没有达到最先进的水平——目前在ImageNet上训练的最好的CNN在没有额外数据的情况下达到了85.8%。尽管有正则化等策略，但由于缺乏关于图像的内置知识，ViT对ImageNet任务的拟合度过高。\n",
    "- **scale up数据集**：在相同数据集上训练ViT和SOTA CNN模型BiT（CNN Big Transfer）并对比效果，当数据集为ImageNet（1M图像）时，ViT的表现明显不如BiT，当数据集为ImageNet-21k（14M图像）时，二者水平相当，当数据集scale up到JFT（300M图像）时，ViT优于BiT；\n",
    "- **scale up计算量**：在JFT上训练了几种不同的ViT模型和CNN。这些模型涵盖了一系列模型大小和训练持续时间。因此，它们需要不同数量的计算来进行训练。我们观察到，对于给定的计算量，ViT的性能优于等效的CNN；"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00046a94",
   "metadata": {},
   "source": [
    "## 参考文献\n",
    "\n",
    "[1] An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. [arxiv](https://arxiv.org/abs/2010.11929)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
